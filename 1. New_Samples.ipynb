{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from api_encoder import get_raw_data\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Scraped Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>csdbId</th>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Csdb__ScamDomains__e4b99f</td>\n",
       "      <td>e4b99f</td>\n",
       "      <td>myelherwallel.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phishing</td>\n",
       "      <td>MyEtherWallet</td>\n",
       "      <td>0xD0cC2B24980CBCCA47EF755Da88B220a82291407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Csdb__ScamDomains__a3ec5b</td>\n",
       "      <td>a3ec5b</td>\n",
       "      <td>etherswap.org</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phishing</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>0x4cdc1cba0aeb5539f2e0ba158281e67e0e54a9b1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Csdb__ScamDomains__91a008</td>\n",
       "      <td>91a008</td>\n",
       "      <td>xn--mytherwallet-fvb.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phishing</td>\n",
       "      <td>MyEtherWallet</td>\n",
       "      <td>0x00e01a648ff41346cdeb873182383333d2184dd1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Csdb__ScamDomains__82a7f6</td>\n",
       "      <td>82a7f6</td>\n",
       "      <td>myethwallet.net</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phishing</td>\n",
       "      <td>MyEtherWallet</td>\n",
       "      <td>0x00e01A648Ff41346CDeB873182383333D2184dd1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Csdb__ScamDomains__1224a2</td>\n",
       "      <td>1224a2</td>\n",
       "      <td>district-0x.io</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fake ICO</td>\n",
       "      <td>district0x</td>\n",
       "      <td>0x240e125c20a4cC84Bd6E7F8D1FD07Aff4c06D43d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id  csdbId                      name  status  \\\n",
       "0  Csdb__ScamDomains__e4b99f  e4b99f         myelherwallel.com     NaN   \n",
       "1  Csdb__ScamDomains__a3ec5b  a3ec5b             etherswap.org     NaN   \n",
       "2  Csdb__ScamDomains__91a008  91a008  xn--mytherwallet-fvb.com     NaN   \n",
       "3  Csdb__ScamDomains__82a7f6  82a7f6           myethwallet.net     NaN   \n",
       "4  Csdb__ScamDomains__1224a2  1224a2            district-0x.io     NaN   \n",
       "\n",
       "   category    subcategory                                     address  \n",
       "0  Phishing  MyEtherWallet  0xD0cC2B24980CBCCA47EF755Da88B220a82291407  \n",
       "1  Phishing       Ethereum  0x4cdc1cba0aeb5539f2e0ba158281e67e0e54a9b1  \n",
       "2  Phishing  MyEtherWallet  0x00e01a648ff41346cdeb873182383333d2184dd1  \n",
       "3  Phishing  MyEtherWallet  0x00e01A648Ff41346CDeB873182383333D2184dd1  \n",
       "4  Fake ICO     district0x  0x240e125c20a4cC84Bd6E7F8D1FD07Aff4c06D43d  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              object\n",
      "csdbId          object\n",
      "name            object\n",
      "status         float64\n",
      "category        object\n",
      "subcategory     object\n",
      "address         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "scraped_df = pd.read_csv('./Data/scraped/non_null_addresses_816.csv')\n",
    "scraped_df['address'] = scraped_df['address'].astype(str)\n",
    "scraped_addresses = list(scraped_df['address'].values)\n",
    "display(scraped_df.head())\n",
    "print(scraped_df.dtypes)\n",
    "\n",
    "\n",
    "# filter out addresses that already exist in the original dataset\n",
    "existing_addresses = df['Address'].unique()\n",
    "scraped_addresses = [add for add in scraped_addresses if add not in existing_addresses]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch All Scraped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "\n",
    "def create_Avg_min_between_received_tnx(data):\n",
    "    # dependent on sent_or_receive, timestamp\n",
    "    if no_received: return [0]\n",
    "    else: \n",
    "        datetimes = pd.to_datetime(data[received_cond]['timeStamp'], unit='s')\n",
    "        if len(datetimes) == 1:\n",
    "            return [0]\n",
    "        else:\n",
    "            datetimes_diff = [datetimes.iloc[i] - datetimes.iloc[i - 1] for i in range(1, len(datetimes))]\n",
    "            minutes_list = [td.total_seconds() / 60 for td in datetimes_diff]\n",
    "            average_minutes = round(sum(minutes_list) / len(minutes_list), 2)\n",
    "            return [average_minutes]\n",
    "\n",
    "def create_Avg_min_between_sent_tnx(data):\n",
    "    # dependent on sent_or_receive, timestamp\n",
    "    if no_sent: return [0]\n",
    "    else: \n",
    "        datetimes = pd.to_datetime(data[sent_cond]['timeStamp'], unit='s')\n",
    "        if len(datetimes) == 1:\n",
    "            return [0]\n",
    "        else:\n",
    "            datetimes_diff = [datetimes.iloc[i] - datetimes.iloc[i - 1] for i in range(1, len(datetimes))]\n",
    "            minutes_list = [td.total_seconds() / 60 for td in datetimes_diff]\n",
    "            average_minutes = round(sum(minutes_list) / len(minutes_list), 2)\n",
    "            return [average_minutes]\n",
    "\n",
    "def create_Sent_tnx(data):\n",
    "    # dependent on sent_or_receive\n",
    "    if no_sent: return [0]\n",
    "    else: return [data[sent_cond].shape[0]]\n",
    "\n",
    "def create_Received_Tnx(data):\n",
    "    # dependent on sent_or_receive\n",
    "    if no_sent: return [len(data)]\n",
    "    else: return [len(data) - sum(sent_cond)]\n",
    "\n",
    "def create_Number_of_Created_Contracts(data):\n",
    "    # dependent on contractAddress\n",
    "    return [sum(data['contractAddress'] != '')]\n",
    "\n",
    "def create_Average_of_Unique_Received_From_Addresses(data):\n",
    "    # dependent on sent_or_receive\n",
    "    if no_received: return [0]\n",
    "    else: return [len(data[received_cond]['from'].unique())]\n",
    "\n",
    "def create_Average_of_Unique_Sent_To_Addresses(data):\n",
    "    # dependent on sent_or_receive\n",
    "    if no_sent: return [0]\n",
    "    else: return [len(data[sent_cond]['to'].unique())]\n",
    "\n",
    "def create_min_max_avg_value_received(data):\n",
    "    # dependent on sent_or_receive, eth_value\n",
    "    if no_received: \n",
    "        min_value_received, max_value_received, avg_val_received = [0], [0], [0]\n",
    "        return min_value_received, max_value_received, avg_val_received\n",
    "    else: \n",
    "        try: min_value_received = [min(data[received_cond]['eth_value'])]\n",
    "        except: print('Error occurred at creating min_value_received')\n",
    "        try: max_value_received = [max(data[received_cond]['eth_value'])]\n",
    "        except: print('Error occurred at creating max_value_received')\n",
    "        try: avg_val_received = [data[received_cond]['eth_value'].mean()]\n",
    "        except: print('Error occurred at creating avg_val_received')\n",
    "        return min_value_received, max_value_received, avg_val_received\n",
    "\n",
    "    \n",
    "def create_min_max_avg_value_sent(data):\n",
    "    # dependent on sent_or_receive, eth_value\n",
    "    if no_sent: \n",
    "        min_value_sent, max_value_sent, avg_val_sent = [0],[0],[0]\n",
    "        return min_value_sent, max_value_sent, avg_val_sent\n",
    "    else: \n",
    "        try: min_value_sent = [min(data[sent_cond]['eth_value'])]\n",
    "        except: print('Error occurred at creating min_value_sent')\n",
    "        try: max_value_sent = [max(data[sent_cond]['eth_value'])]\n",
    "        except: print('Error occurred at creating max_value_sent')\n",
    "        try: avg_val_sent = [data[sent_cond]['eth_value'].mean()]\n",
    "        except: print('Error occurred at creating avg_val_sent')\n",
    "        return min_value_sent, max_value_sent, avg_val_sent\n",
    "\n",
    "\n",
    "def create_total_transactions_including_tnx_to_create_contract(data):\n",
    "    return [data.shape[0]]\n",
    "    \n",
    "def create_total_Ether_sent(data):\n",
    "    # dependent on sent_or_receive, eth_value\n",
    "    if no_sent: return [0]\n",
    "    else: return [round(data[sent_cond]['eth_value'].sum(), 6)]\n",
    "\n",
    "\n",
    "def create_total_ether_received(data):\n",
    "    # dependent on sent_or_receive, eth_value\n",
    "    if no_received: return [0]\n",
    "    else: return [round(data[received_cond]['eth_value'].sum(), 6)]\n",
    "\n",
    "def create_total_ether_balance(data):\n",
    "    return [round(data[received_cond]['eth_value'].sum() - data[sent_cond]['eth_value'].sum(), 6)]\n",
    "    \n",
    "''' ######################################################################################## '''\n",
    "\n",
    "def reconstruct(address, data):\n",
    "\n",
    "    new_df = pd.DataFrame()\n",
    "    \n",
    "    # create address feature\n",
    "    new_df['Address'] = [address]\n",
    "    # create target feature\n",
    "    new_df['Flag'] = [1]\n",
    "    # create other features\n",
    "    try: new_df['Avg_min_between_received_tnx'] = create_Avg_min_between_received_tnx(data=data)\n",
    "    except: print('Error occurred when creating Avg_min_between_received_tnx')\n",
    "\n",
    "    try: new_df['Avg_min_between_sent_tnx'] = create_Avg_min_between_sent_tnx(data=data)\n",
    "    except: print('Error occurred when creating Avg_min_between_sent_tnx')\n",
    "\n",
    "    try: new_df['Sent_tnx'] = create_Sent_tnx(data=data)\n",
    "    except: print('Error occurred when creating Sent_tnx')\n",
    "\n",
    "    try: new_df['Received_Tnx'] = create_Received_Tnx(data=data)\n",
    "    except: print('Error occurred when creating Received_Tnx')\n",
    "\n",
    "    try: new_df['Number_of_Created_Contracts'] = create_Number_of_Created_Contracts(data=data)\n",
    "    except: print('Error occurred when creating Number_of_Created_Contracts')\n",
    "\n",
    "    try: new_df['Average_of_Unique_Received_From_Addresses'] = create_Average_of_Unique_Received_From_Addresses(data=data)\n",
    "    except: print('Error occurred when creating Average_of_Unique_Received_From_Addresses')\n",
    "    \n",
    "    try: new_df['Average_of_Unique_Sent_To_Addresses'] = create_Average_of_Unique_Sent_To_Addresses(data=data)\n",
    "    except: print('Error occurred when creating Average_of_Unique_Sent_To_Addresses')\n",
    "\n",
    "    try: new_df['min_value_received'], new_df['max_value_received'], new_df['avg_value_received'] = create_min_max_avg_value_received(data=data)\n",
    "    except: print('Error occurred when creating min_max_avg_value_received')\n",
    "\n",
    "    try: new_df['min_value_sent'], new_df['max_value_sent'], new_df['avg_value_sent'] = create_min_max_avg_value_sent(data=data)\n",
    "    except: print('Error occurred when creating min_max_avg_value_sent')\n",
    "\n",
    "    try: new_df['total_transactions_including_tnx_to_create_contract'] = create_total_transactions_including_tnx_to_create_contract(data=data)\n",
    "    except: print('Error occurred when creating total_transactions_including_tnx_to_create_contract')\n",
    "\n",
    "    try: new_df['total_Ether_sent'] = create_total_Ether_sent(data=data)\n",
    "    except: print('Error occurred when creating total_Ether_sent')\n",
    "\n",
    "    try: new_df['total_ether_received'] = create_total_ether_received(data=data)\n",
    "    except: print('Error occurred when creating total_ether_received')\n",
    "\n",
    "    try: new_df['total_ether_balance'] = create_total_ether_balance(data=data)\n",
    "    except: print('Error occurred when creating total_ether_balance')\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 10/679 [04:39<10:15:58, 55.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for sample 9: HTTPSConnectionPool(host='api.etherscan.io', port=443): Read timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 21/679 [06:01<3:56:35, 21.57s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 20 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 41/679 [07:54<3:33:01, 20.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 40 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 54/679 [09:34<3:27:41, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 53 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 142/679 [16:00<3:22:51, 22.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 141 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 144/679 [17:05<4:30:28, 30.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 143 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 158/679 [20:05<4:06:53, 28.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 157 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 170/679 [22:00<3:33:02, 25.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 169 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 173/679 [23:03<3:48:59, 27.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 172 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 224/679 [26:52<2:24:21, 19.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 223 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 250/679 [30:09<2:38:45, 22.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 249 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 262/679 [32:49<2:20:33, 20.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 261 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 263/679 [33:50<3:45:34, 32.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 262 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 275/679 [35:09<2:11:52, 19.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 274 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 297/679 [37:51<2:32:29, 23.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 296 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 330/679 [40:53<1:52:55, 19.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 329 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 334/679 [41:11<54:52,  9.54s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for sample 333: DataFrame constructor not properly called!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 352/679 [43:16<1:59:53, 22.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 351 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 374/679 [46:46<2:05:52, 24.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 373 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 382/679 [47:14<18:44,  3.79s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for sample 381: DataFrame constructor not properly called!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 388/679 [48:52<2:08:56, 26.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 387 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 393/679 [50:05<1:58:04, 24.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 392 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 440/679 [55:40<2:47:47, 42.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for sample 439: HTTPSConnectionPool(host='api.etherscan.io', port=443): Read timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 473/679 [1:01:59<1:10:02, 20.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 472 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 494/679 [1:04:54<1:21:23, 26.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 493 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 499/679 [1:06:00<1:09:36, 23.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 498 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 629/679 [1:16:02<23:34, 28.29s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 628 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 642/679 [1:18:14<13:42, 22.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 641 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 643/679 [1:19:15<20:23, 33.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 642 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 672/679 [1:22:14<02:45, 23.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for sample 671 took more than 1 minute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 679/679 [1:22:32<00:00,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Number of samples successfully transformed:  523\n",
      "Number of samples without any data:  126\n",
      "Number of samples that were timed out:  26\n",
      "Number of samples that were unsuccessful:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#####\n",
    "\n",
    "# test a few samples\n",
    "\n",
    "successful_data = []\n",
    "no_data = []\n",
    "timeout_data = []\n",
    "sample_dfs = []\n",
    "\n",
    "scraped_dfs = pd.DataFrame()\n",
    "for i, addr in tqdm(enumerate(scraped_addresses), total=len(scraped_addresses)): \n",
    "    try: \n",
    "        sample = pd.DataFrame(get_raw_data(address=addr))\n",
    "        if sample.empty:\n",
    "            # save samples without data\n",
    "            no_data.append(i) \n",
    "            continue\n",
    "        else:\n",
    "            # save samples original data\n",
    "            sample_dfs.append(sample)\n",
    "            \n",
    "            # reconstruct data\n",
    "            addr_lc, addr_uc = addr.lower(), addr.upper()\n",
    "\n",
    "            sample['sent_or_receive'] = ((sample['from'] == addr_lc) | (sample['from'] == addr_uc)).map({True: 'sent', False: 'received'})\n",
    "            sample['eth_value'] = sample['value'].astype(float) / (10**18)\n",
    "            received_cond = sample['sent_or_receive']=='received'\n",
    "            sent_cond = sample['sent_or_receive']=='sent'\n",
    "            no_received = sample[sample['sent_or_receive']=='received'].empty\n",
    "            no_sent = sample[sample['sent_or_receive']=='sent'].empty\n",
    "\n",
    "            try: sample = reconstruct(addr, sample)\n",
    "            except: print(f'Error occurred at sample {i}:\\n')\n",
    "            scraped_dfs = pd.concat([scraped_dfs, sample], axis=0)\n",
    "\n",
    "            # save successful samples\n",
    "            successful_data.append(i)\n",
    "            \n",
    "    except requests.Timeout: \n",
    "        # save samples that take too long\n",
    "        timeout_data.append(i)\n",
    "        print(f'Fetching data for sample {i} took more than 1 minute.')\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for sample {i}: {e}\")\n",
    "\n",
    "print('#'*50)\n",
    "print('Number of samples successfully transformed: ', len(successful_data))\n",
    "print('Number of samples without any data: ', len(no_data))\n",
    "print('Number of samples that were timed out: ', len(timeout_data))\n",
    "unsuccessful_data = [i for i in range(len(scraped_addresses)) if (i not in successful_data) & (i not in no_data ) & (i not in timeout_data)]\n",
    "print('Number of samples that were unsuccessful: ', len(unsuccessful_data))\n",
    "# for i in range(len(sample_df)): print(f'Dimensions of Sample {i}: ', sample_df[i].shape)\n",
    "\n",
    "# sample_df = pd.concat(sample_df, axis=0)\n",
    "# display(sample_df.head())\n",
    "# print(sample_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(523, 19)\n",
      "(21057, 22)\n"
     ]
    }
   ],
   "source": [
    "sample_dfs = pd.concat(sample_dfs)\n",
    "print(scraped_dfs.shape)\n",
    "print(sample_dfs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_dfs.to_csv('new_samples_aggregated.csv')\n",
    "sample_dfs.to_csv('new_samples_all.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
